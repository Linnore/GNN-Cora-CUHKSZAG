{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da06ae01-7103-4aea-9c0f-4ef08895d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import Data\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "import torch_geometric.transforms as T\n",
    "import torch_geometric.data as geom_data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14853797-491b-4067-8b3b-73f096d30cfb",
   "metadata": {},
   "source": [
    "#### Configure device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "115df4c7-0c22-4fa1-9865-9980670d4432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda', index=0), 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device != \"cpu\":\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "    \n",
    "num_workers = os.cpu_count()\n",
    "device, num_workers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d612b950-88b7-4d99-b2ee-6537f7ee738d",
   "metadata": {},
   "source": [
    "### Directory configuration and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e824ef20-6156-49c3-bfa9-47eea7af9124",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "tb_logging_dir = os.path.join(cwd, \"lightning_logs\")\n",
    "exp_name = \"Cora-GraphSAGE-transductive\"\n",
    "exp_dir = os.path.join(tb_logging_dir, exp_name)\n",
    "dataset_dir = os.path.join(cwd, \"dataset\", \"Cora\")\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.makedirs(dataset_dir)\n",
    "    \n",
    "CoraDataset = Planetoid(\n",
    "    root=\"dataset/Cora\", name=\"Cora\", split=\"full\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a30e50",
   "metadata": {},
   "source": [
    "#### Note that if numebr of epoch is large, the kernel will stuck after training! Need to load the saved model mannually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "330ea05d-a1f8-49e4-afb3-c4a71b750d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoints to D:\\GitHub\\aml-project\\GNN\\zyq\\lightning_logs\\Cora-GraphSAGE-transductive\\version_14\\checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | aggr  | MaxAggregation    | 0     \n",
      "1 | model | Sequential_24e3a6 | 324 K \n",
      "--------------------------------------------\n",
      "324 K     Trainable params\n",
      "0         Non-trainable params\n",
      "324 K     Total params\n",
      "1.299     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Processing Done on: cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\torchGNN\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "D:\\Anaconda\\envs\\torchGNN\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41ffdbcdbd44c77ab2e07d47fb34319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "D:\\Anaconda\\envs\\torchGNN\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15388c2e723a46a48422e20d9d21e247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9663226088156428     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5210734009742737     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9663226088156428    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5210734009742737    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.5210734009742737, 'test_acc': 0.9663226088156428}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.model.RS_GraphSAGE import GraphSage\n",
    "\n",
    "dataset = CoraDataset\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.00,\n",
    "    patience=5,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")\n",
    "hparams = {\"aggregator_type\": 'max',\n",
    "           \"HIDDEN_DIM\": [112, 16],  # size of the embedding\n",
    "           \"BATCH_SIZE\": 64,\n",
    "           \"LEARNING_RATE\": 0.001,\n",
    "           \"NUM_NEIGHBORS\": [10, 10]\n",
    "           }  # The number of neighbors in each order of sampling\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger(tb_logging_dir, name=exp_name)\n",
    " \n",
    "trainer = pl.Trainer(max_epochs=100,\n",
    "                     callbacks=[early_stop_callback],\n",
    "                     logger=tb_logger,\n",
    "                     log_every_n_steps=1,\n",
    "                     # accelerator=\"cpu\"\n",
    "                    # num_sanity_val_steps = 0\n",
    "                     )\n",
    "\n",
    "version_dir = os.path.join(\n",
    "    exp_dir, \"version_\"+str(trainer.logger.version))\n",
    "writer_acc = SummaryWriter(log_dir=version_dir)\n",
    "writer_loss = SummaryWriter(log_dir=version_dir)\n",
    "\n",
    "checkpoint_dir = os.path.join(version_dir, \"checkpoints\")\n",
    "print(\"Saving checkpoints to\", checkpoint_dir)\n",
    "\n",
    "SAGEmodel = GraphSage(dataset=dataset, input_dim=dataset.num_features, hparams=hparams, \n",
    "                      writer_acc=writer_acc, writer_loss=writer_loss).to(device)\n",
    "SAGEmodel.data_processing_transductive()\n",
    "\n",
    "trainer.fit(SAGEmodel)\n",
    "trainer.test(SAGEmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a956fe61-7c9a-4907-af91-227a203a468d",
   "metadata": {},
   "source": [
    "#### Upload trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b87e18-066d-4b06-85a2-fc5379bd64a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model.RS_GraphSAGE import GraphSage\n",
    "\n",
    "hparams = {\"aggregator_type\": 'max',\n",
    "           \"HIDDEN_DIM\": [112, 16],  # size of the embedding\n",
    "           \"BATCH_SIZE\": 64,\n",
    "           \"LEARNING_RATE\": 0.001,\n",
    "           \"NUM_NEIGHBORS\": [10, 10]\n",
    "           }  # The number of neighbors in each order of sampling\n",
    "\n",
    "dataset = AGDataset\n",
    "checkpoint_dir = \"D:\\\\GitHub\\\\aml-project\\\\GNN\\\\zyq\\\\lightning_logs\\\\Cora-GraphSAGE-transductive\\\\version_14\\\\checkpoints\"\n",
    "checkpoint_file = os.path.join(checkpoint_dir, os.listdir(checkpoint_dir)[0])\n",
    "Loaded_model = GraphSage.load_from_checkpoint(\n",
    "    checkpoint_file, dataset=dataset, input_dim=dataset.num_features, hparams=hparams\n",
    ")\n",
    "Loaded_model.data_processing_transductive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af799c41-fcfd-4c7f-a507-478c5dcc8429",
   "metadata": {},
   "source": [
    "#### To see the mini-batch's number of negative edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fa1d06a-6be9-4e28-a81b-c624e50f3b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2449, 1433], edge_index=[2, 6160], edge_label=[6160], train_mask=[2449], n_id=[2449], e_id=[6160], input_id=[64], batch_size=64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpLoader = Loaded_model.train_dataloader()\n",
    "sample = next(iter(tmpLoader))\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f755f-4625-467c-9295-7d1213e2d5b5",
   "metadata": {},
   "source": [
    "#### To see the number of training positive edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efb1b659-8018-4d9e-833b-d4c8d467a17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 4708], edge_label=[4708], train_mask=[2708])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loaded_model.pos_data[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b99a04-0194-4291-afc1-32c1a568409b",
   "metadata": {},
   "source": [
    "#### Recommendation by transductive for a given node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16ad1186-86ab-41f3-938a-86cc2c2c6ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation for node 1676\n",
      "2109 0.9991366267204285\n",
      "1973 0.9991214871406555\n",
      "921 0.9988411068916321\n",
      "175 0.9987137317657471\n",
      "1464 0.9986955523490906\n",
      "2485 0.9985242486000061\n",
      "1013 0.9984639883041382\n",
      "1421 0.9983038902282715\n",
      "1616 0.9982099533081055\n",
      "955 0.9981825351715088\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "def recommendation_by_transductive_model(A, model):\n",
    "    ## Return recommedation for A in the given graph\n",
    "    neg_graph = model.neg_data[\"all\"]\n",
    "    candidate = torch.zeros(neg_graph.num_edges)\n",
    "\n",
    "    candidate = neg_graph.edge_index[1, (neg_graph.edge_index[0] == A)].cpu()\n",
    "    candidate.sort()\n",
    "    num_candidates = len(candidate) \n",
    "    u = torch.ones(num_candidates, dtype=torch.int) * A\n",
    "    v = torch.Tensor(candidate)\n",
    "    candidate_link = torch.stack((u, v))\n",
    "\n",
    "    embedding = model(model.pos_data[\"all\"].x, model.pos_data[\"all\"].edge_index)\n",
    "\n",
    "    scores = np.zeros(candidate.max()+1) - 1e8\n",
    "    \n",
    "    scores[v] = F.sigmoid((embedding[u] * embedding[v]).sum(dim=1)).detach().numpy()\n",
    "\n",
    "    rank_idx = np.argsort(scores)[::-1]\n",
    "    print(\"Recommendation for node\", A)\n",
    "    for k in range(10):\n",
    "        print(rank_idx[k], scores[rank_idx[k]])\n",
    "        \n",
    "recommendation_by_transductive_model(1676, Loaded_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bee65f-d840-4809-bfe7-1e8c7808f5ea",
   "metadata": {},
   "source": [
    "#### Recommendation by inductive for a given node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09d219e0-5341-4ce8-87fd-23125365e22e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Anaconda\\envs\\torchGNN\\lib\\site-packages\\torch_geometric\\data\\storage.py:78\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\torchGNN\\lib\\site-packages\\torch_geometric\\data\\storage.py:103\u001b[0m, in \u001b[0;36mBaseStorage.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'title'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28mprint\u001b[39m(rank_idx[k], scores[rank_idx[k]], pos_graph\u001b[38;5;241m.\u001b[39mtitle[rank_idx[k]])\n\u001b[1;32m---> 27\u001b[0m \u001b[43mrecommendation_by_inductive_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1676\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLoaded_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 23\u001b[0m, in \u001b[0;36mrecommendation_by_inductive_model\u001b[1;34m(A, model)\u001b[0m\n\u001b[0;32m     20\u001b[0m rank_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(scores)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     22\u001b[0m pos_graph \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpos_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommendation for node\u001b[39m\u001b[38;5;124m\"\u001b[39m, A, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith title\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mpos_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtitle\u001b[49m[A])\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(rank_idx[k], scores[rank_idx[k]], pos_graph\u001b[38;5;241m.\u001b[39mtitle[rank_idx[k]])\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\torchGNN\\lib\\site-packages\\torch_geometric\\data\\data.py:441\u001b[0m, in \u001b[0;36mData.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_store\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object was created by an older version of PyG. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    438\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf this error occurred while loading an already existing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    439\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset, remove the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directory in the dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot folder and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\torchGNN\\lib\\site-packages\\torch_geometric\\data\\storage.py:80\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'title'"
     ]
    }
   ],
   "source": [
    "# import torch.nn.functional as F\n",
    "# def recommendation_by_inductive_model(A, model):\n",
    "#     ## Return recommedation for A in the given graph\n",
    "#     neg_graph = model.neg_data[\"all\"]\n",
    "#     candidate = torch.zeros(neg_graph.num_edges)\n",
    "\n",
    "#     candidate = neg_graph.edge_index[1, (neg_graph.edge_index[0] == A)].cpu()\n",
    "#     candidate.sort()\n",
    "#     num_candidates = len(candidate) \n",
    "#     u = torch.ones(num_candidates, dtype=torch.int) * A\n",
    "#     v = torch.Tensor(candidate)\n",
    "#     candidate_link = torch.stack((u, v))\n",
    "\n",
    "#     embedding = model(model.pos_data[\"all\"].x, model.pos_data[\"all\"].edge_index)\n",
    "\n",
    "#     scores = np.zeros(candidate.max()+1) - 1e8\n",
    "    \n",
    "#     scores[v] = F.sigmoid((embedding[u] * embedding[v]).sum(dim=1)).detach().numpy()\n",
    "\n",
    "#     rank_idx = np.argsort(scores)[::-1]\n",
    "    \n",
    "#     pos_graph = model.pos_data[\"all\"]\n",
    "#     print(\"Recommendation for node\", A, \"with title\", pos_graph.title[A])\n",
    "#     for k in range(10):\n",
    "#         print(rank_idx[k], scores[rank_idx[k]], pos_graph.title[rank_idx[k]])\n",
    "        \n",
    "# recommendation_by_inductive_model(1676, Loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1017b0-4f63-4479-8b63-71ef910d8495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
